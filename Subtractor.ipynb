{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    def __init__(self, chars=\"0123456789+-\"):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.ansChars = sorted(set('0123456789'))\n",
    "        \n",
    "        # build correspondence table between char and index of encoding\n",
    "        self.charToIndex = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indexToChar = dict((i ,c) for i, c in enumerate(self.chars))\n",
    "        self.ansCharsToIndex =  dict((c, i) for i, c in enumerate(self.ansChars))\n",
    "        self.indexToAnsChars = dict((i ,c) for i, c in enumerate(self.ansChars))\n",
    "\n",
    "    def encode(self, expr, rowsNum, type):\n",
    "        if type == \"expr\":\n",
    "            x = np.zeros(shape=(rowsNum, len(self.chars)))\n",
    "            for i, c in enumerate(expr):\n",
    "                x[i, self.charToIndex[c]] = 1\n",
    "        elif type == \"ans\":\n",
    "            x = np.zeros(shape=(rowsNum, len(self.ansChars))) # +1 for the sign bit in ans\n",
    "            for i, c in enumerate(expr):\n",
    "                x[i, self.ansCharsToIndex[c]] = 1\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, type, argmax=True):\n",
    "        if argmax:\n",
    "            # get the index of max value(=1) of each row\n",
    "            x = x.argmax(axis=1)\n",
    "        # then look up table to decode\n",
    "        if type == \"expr\":\n",
    "            return \"\".join(self.indexToChar[i] for i in x)\n",
    "        elif type == \"ans\":\n",
    "            return \"\".join(self.indexToAnsChars[i] for i in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(quesSize=150000, digits=3):\n",
    "    questions = []\n",
    "    expected = []\n",
    "    seen = set()\n",
    "\n",
    "    print('Generating data...')\n",
    "    \n",
    "    func = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, digits + 1))))\n",
    "    while len(questions) < quesSize:\n",
    "        a, b = func(), func()\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        \n",
    "        if random.randint(0, 99) % 2 == 0:\n",
    "            e = str(a).zfill(digits) + '-' + str(b).zfill(digits)\n",
    "            #e = '{}-{}'.format(a, b)\n",
    "            ans = str(a - b)\n",
    "        else:\n",
    "            e = str(a).zfill(digits) + '+' + str(b).zfill(digits)\n",
    "            ans = str(a + b).zfill(4)\n",
    "        \n",
    "        #expression = e + \" \" * ((2 * digits + 1) - len(e))\n",
    "        #ans += \" \" * (digits + 2 - len(ans)) # `+2` for the carry and the minus sign.\n",
    "        ans = \"1\" + ans[1:].zfill(4) if int(ans) < 0 else \"0\" + ans.zfill(4)\n",
    "\n",
    "        questions.append(e)\n",
    "        expected.append(ans)\n",
    "    \n",
    "    \n",
    "    print('Generating data complete.')\n",
    "    print('Total questions:', len(questions))\n",
    "    return questions, expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation\n",
    "* One-hot encoding\n",
    "    * May use `to_categorical` method\n",
    "    * But here I encoded the data myself using modified character table in example\n",
    "* I've modified the example for subtraction but it's not so good\n",
    "    * The whitespace's dimension in encoding may influence the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorize(questions, expected, ctable, digits=3):\n",
    "    print('Vectorization begin...')\n",
    "    \n",
    "    MAXLEN = 2 * digits + 1\n",
    "    x = np.zeros((len(questions), MAXLEN, len(ctable.chars)))\n",
    "    y = np.zeros((len(expected), digits + 2, len(ctable.ansChars)))\n",
    "\n",
    "    # encoding the each char in expression/answer to boolean value\n",
    "    for i, sentence in enumerate(questions):\n",
    "        x[i] = ctable.encode(sentence, MAXLEN, \"expr\")\n",
    "    for i, sentence in enumerate(expected):\n",
    "        y[i] = ctable.encode(sentence, digits + 2, \"ans\")\n",
    "    \n",
    "    print('Vectorization complete')\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Generating data complete.\n",
      "Total questions: 150000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['066-023', '812+071', '046-006', '264-306', '034-158']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions, expected = genData()\n",
    "questions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoding of questions and expected answer are **different**\n",
    "* **Use first bit as a sign bit** in expected answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00043', '00883', '00040', '10042', '10124']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+': 0,\n",
       " '-': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable = CharacterTable()\n",
    "ctable.charToIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization begin...\n",
      "Vectorization complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = Vectorize(questions, expected, ctable)\n",
    "x[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For 045 - 365, by looking up charToIndex table to set corresponding index value as 1\n",
    "    - 0   \\[0 0 1 0 0 0 0 0 0 0 0 0\\]\n",
    "    - 4   \\[0 0 0 0 0 0 1 0 0 0 0 0\\]\n",
    "    - 5   \\[0 0 0 0 0 0 0 1 0 0 0 0\\]\n",
    "    - \\-    \\[0 1 0 0 0 0 0 0 0 0 0 0\\]\n",
    "    - 3   \\[0 0 0 0 0 1 0 0 0 0 0 0\\]\n",
    "    - 6   \\[0 0 0 0 0 0 0 0 1 0 0 0\\]\n",
    "    - 5   \\[0 0 0 0 0 0 0 1 0 0 0 0\\]\n",
    "* Same for 299 + 396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 藉由一個 digit 來表示正負號\n",
    "    * 045 - 365 = 10320 第一位數 1 表示 sign bit `-`, encoding 中第一位數的 index1 會被設為 1\n",
    "    * 299 + 396 = 00695 第一位數 0 表示 sign bit `+`, encoding 中第一位數的 index0 會被設為 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(x, y, splitAt=120000):\n",
    "\n",
    "    # train_test_split\n",
    "    train_x = x[:splitAt]\n",
    "    train_y = y[:splitAt]\n",
    "    test_x = x[splitAt:]\n",
    "    test_y = y[splitAt:]\n",
    "\n",
    "    # train validation split for RNN\n",
    "    # splitAt = len(train_x) - len(train_x) // 10\n",
    "    # (val_x, train_x) = train_x[splitAt:], train_x[:splitAt]\n",
    "    # (val_y, train_y) = train_y[splitAt:], train_y[:splitAt]\n",
    "\n",
    "    # return ((train_x, train_y), (val_x, val_y), (test_x, test_y))\n",
    "    return ((train_x, train_y), (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(120000, 7, 12)\n",
      "(120000, 5, 10)\n",
      "Testing Data:\n",
      "(30000, 7, 12)\n",
      "(30000, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "((train_x, train_y), (test_x, test_y)) = splitData(x, y)\n",
    "\n",
    "print('Training Data:')\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print('Testing Data:')\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('066-023', '00043')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctable.decode(x[0], type=\"expr\"), ctable.decode(y[0], type=\"ans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "* I train two model for outputs of the sign and the numeric part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(train_x, train_y):\n",
    "    print('Build model...')\n",
    "    HIDDEN_SIZE = 128\n",
    "    BATCH_SIZE = 128\n",
    "    digits = 3\n",
    "    \n",
    "    # flattern the data\n",
    "    train_x = train_x.reshape(len(train_x), -1) # 7 * 12 -> 1 * 84\n",
    "    print(train_x.shape)\n",
    "\n",
    "    train_y_sign = train_y[:, 0, :2].reshape(len(train_y), -1)\n",
    "    train_y_num = train_y[:, 1:len(train_y), :].reshape(len(train_y), -1)\n",
    "    print(train_y_num.shape)\n",
    "    print(train_y_sign.shape)\n",
    "    \n",
    "    modelOfNums = Sequential()\n",
    "    modelOfNums.add(layers.Dense(250 , input_shape=(84,), activation='relu'))\n",
    "    modelOfNums.add(layers.Dense(250, activation='relu'))\n",
    "    modelOfNums.add(layers.Dense(150, activation='relu'))\n",
    "    modelOfNums.add(layers.Dense(100, activation='relu'))\n",
    "    modelOfNums.add(layers.Dense(4*10, activation='sigmoid'))\n",
    "    modelOfNums.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    modelOfNums.fit(train_x, train_y_num,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2, \n",
    "                    shuffle=True, verbose=1, epochs=100)\n",
    "    \n",
    "    modelOfSign = Sequential()\n",
    "    modelOfSign.add(layers.Dense(250 , input_shape=(84,), activation='relu'))\n",
    "    modelOfSign.add(layers.Dense(250, activation='relu'))\n",
    "    modelOfSign.add(layers.Dense(150, activation='relu'))\n",
    "    modelOfSign.add(layers.Dense(50, activation='relu'))\n",
    "    modelOfSign.add(layers.Dense(2, activation='sigmoid'))\n",
    "    modelOfSign.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "    modelOfSign.fit(train_x, train_y_sign,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2, \n",
    "                    shuffle=True, verbose=1, epochs=80)\n",
    "    \n",
    "    return modelOfNums, modelOfSign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `tranform()` to change the data representation of the answers into int value for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(ans):\n",
    "    if ans[0] == '1':\n",
    "        ans = \"-\" + ans[1:len(ans)]\n",
    "    return int(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with testing data...\n",
      "Build model...\n",
      "(120000, 84)\n",
      "(120000, 40)\n",
      "(120000, 2)\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "96000/96000 [==============================] - 15s 155us/step - loss: 10.9284 - acc: 0.8806 - val_loss: 9.7104 - val_acc: 0.8186\n",
      "Epoch 2/100\n",
      "96000/96000 [==============================] - 11s 110us/step - loss: 8.7047 - acc: 0.8826 - val_loss: 8.0295 - val_acc: 0.8186\n",
      "Epoch 3/100\n",
      "96000/96000 [==============================] - 9s 97us/step - loss: 7.4135 - acc: 0.8826 - val_loss: 7.2389 - val_acc: 0.8186\n",
      "Epoch 4/100\n",
      "96000/96000 [==============================] - 10s 105us/step - loss: 6.8731 - acc: 0.8826 - val_loss: 6.8743 - val_acc: 0.8186\n",
      "Epoch 5/100\n",
      "96000/96000 [==============================] - 9s 97us/step - loss: 6.5506 - acc: 0.8826 - val_loss: 6.5747 - val_acc: 0.8186\n",
      "Epoch 6/100\n",
      "96000/96000 [==============================] - 7s 75us/step - loss: 6.3192 - acc: 0.8826 - val_loss: 6.3965 - val_acc: 0.8186\n",
      "Epoch 7/100\n",
      "96000/96000 [==============================] - 9s 90us/step - loss: 6.2005 - acc: 0.8826 - val_loss: 6.2893 - val_acc: 0.8186\n",
      "Epoch 8/100\n",
      "96000/96000 [==============================] - 10s 102us/step - loss: 6.1078 - acc: 0.8826 - val_loss: 6.2018 - val_acc: 0.8186\n",
      "Epoch 9/100\n",
      "96000/96000 [==============================] - 11s 117us/step - loss: 6.0373 - acc: 0.8826 - val_loss: 6.1420 - val_acc: 0.8186\n",
      "Epoch 10/100\n",
      "96000/96000 [==============================] - 9s 89us/step - loss: 5.9735 - acc: 0.8826 - val_loss: 6.1517 - val_acc: 0.8186\n",
      "Epoch 11/100\n",
      "96000/96000 [==============================] - 9s 89us/step - loss: 5.9151 - acc: 0.8826 - val_loss: 6.0186 - val_acc: 0.8186\n",
      "Epoch 12/100\n",
      "96000/96000 [==============================] - 9s 92us/step - loss: 5.8813 - acc: 0.8826 - val_loss: 6.0152 - val_acc: 0.8186\n",
      "Epoch 13/100\n",
      "96000/96000 [==============================] - 9s 89us/step - loss: 5.8435 - acc: 0.8826 - val_loss: 5.9432 - val_acc: 0.8186\n",
      "Epoch 14/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.8145 - acc: 0.8826 - val_loss: 5.9243 - val_acc: 0.8186\n",
      "Epoch 15/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.7922 - acc: 0.8826 - val_loss: 5.9508 - val_acc: 0.8186\n",
      "Epoch 16/100\n",
      "96000/96000 [==============================] - 9s 94us/step - loss: 5.7769 - acc: 0.8826 - val_loss: 5.9198 - val_acc: 0.8186\n",
      "Epoch 17/100\n",
      "96000/96000 [==============================] - 10s 99us/step - loss: 5.7663 - acc: 0.8826 - val_loss: 5.8846 - val_acc: 0.8186\n",
      "Epoch 18/100\n",
      "96000/96000 [==============================] - 10s 99us/step - loss: 5.7498 - acc: 0.8826 - val_loss: 5.8329 - val_acc: 0.8186\n",
      "Epoch 19/100\n",
      "96000/96000 [==============================] - 9s 98us/step - loss: 5.7417 - acc: 0.8826 - val_loss: 5.8689 - val_acc: 0.8186\n",
      "Epoch 20/100\n",
      "96000/96000 [==============================] - 10s 101us/step - loss: 5.7415 - acc: 0.8826 - val_loss: 5.8716 - val_acc: 0.8186\n",
      "Epoch 21/100\n",
      "96000/96000 [==============================] - 9s 99us/step - loss: 5.7338 - acc: 0.8826 - val_loss: 5.8641 - val_acc: 0.8186\n",
      "Epoch 22/100\n",
      "96000/96000 [==============================] - 9s 99us/step - loss: 5.7138 - acc: 0.8826 - val_loss: 5.8153 - val_acc: 0.8186\n",
      "Epoch 23/100\n",
      "96000/96000 [==============================] - 9s 98us/step - loss: 5.7257 - acc: 0.8826 - val_loss: 5.8258 - val_acc: 0.8186\n",
      "Epoch 24/100\n",
      "96000/96000 [==============================] - 10s 100us/step - loss: 5.7157 - acc: 0.8826 - val_loss: 5.8279 - val_acc: 0.8186\n",
      "Epoch 25/100\n",
      "96000/96000 [==============================] - 9s 95us/step - loss: 5.7048 - acc: 0.8826 - val_loss: 5.8051 - val_acc: 0.8186\n",
      "Epoch 26/100\n",
      "96000/96000 [==============================] - 9s 94us/step - loss: 5.7020 - acc: 0.8826 - val_loss: 5.7963 - val_acc: 0.8186\n",
      "Epoch 27/100\n",
      "96000/96000 [==============================] - 9s 99us/step - loss: 5.7159 - acc: 0.8826 - val_loss: 5.8481 - val_acc: 0.8186\n",
      "Epoch 28/100\n",
      "96000/96000 [==============================] - 9s 97us/step - loss: 5.6958 - acc: 0.8826 - val_loss: 5.7879 - val_acc: 0.8186\n",
      "Epoch 29/100\n",
      "96000/96000 [==============================] - 10s 100us/step - loss: 5.6904 - acc: 0.8826 - val_loss: 5.7997 - val_acc: 0.8186\n",
      "Epoch 30/100\n",
      "96000/96000 [==============================] - 10s 100us/step - loss: 5.7009 - acc: 0.8826 - val_loss: 5.7878 - val_acc: 0.8186\n",
      "Epoch 31/100\n",
      "96000/96000 [==============================] - 10s 101us/step - loss: 5.6928 - acc: 0.8416 - val_loss: 5.6380 - val_acc: 0.4742\n",
      "Epoch 32/100\n",
      "96000/96000 [==============================] - 10s 101us/step - loss: 5.5928 - acc: 0.4015 - val_loss: 5.6433 - val_acc: 0.5258\n",
      "Epoch 33/100\n",
      "96000/96000 [==============================] - 9s 98us/step - loss: 5.5794 - acc: 0.3676 - val_loss: 5.6213 - val_acc: 0.4012\n",
      "Epoch 34/100\n",
      "96000/96000 [==============================] - 10s 99us/step - loss: 5.5869 - acc: 0.4009 - val_loss: 5.6619 - val_acc: 0.3948\n",
      "Epoch 35/100\n",
      "96000/96000 [==============================] - 9s 95us/step - loss: 5.5823 - acc: 0.4402 - val_loss: 5.6262 - val_acc: 0.4236\n",
      "Epoch 36/100\n",
      "96000/96000 [==============================] - 9s 94us/step - loss: 5.5895 - acc: 0.5268 - val_loss: 5.6489 - val_acc: 0.4517\n",
      "Epoch 37/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5720 - acc: 0.5018 - val_loss: 5.6989 - val_acc: 0.4983\n",
      "Epoch 38/100\n",
      "96000/96000 [==============================] - 9s 92us/step - loss: 5.5823 - acc: 0.5329 - val_loss: 5.6358 - val_acc: 0.5248\n",
      "Epoch 39/100\n",
      "96000/96000 [==============================] - 9s 91us/step - loss: 5.5814 - acc: 0.5791 - val_loss: 5.6165 - val_acc: 0.4615\n",
      "Epoch 40/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.5793 - acc: 0.5934 - val_loss: 5.6256 - val_acc: 0.5876\n",
      "Epoch 41/100\n",
      "96000/96000 [==============================] - 9s 97us/step - loss: 5.5702 - acc: 0.6489 - val_loss: 5.6202 - val_acc: 0.6516\n",
      "Epoch 42/100\n",
      "96000/96000 [==============================] - 9s 95us/step - loss: 5.5771 - acc: 0.6323 - val_loss: 5.6120 - val_acc: 0.7837\n",
      "Epoch 43/100\n",
      "96000/96000 [==============================] - 9s 94us/step - loss: 5.5723 - acc: 0.6259 - val_loss: 5.5985 - val_acc: 0.6052\n",
      "Epoch 44/100\n",
      "96000/96000 [==============================] - 9s 95us/step - loss: 5.5732 - acc: 0.6739 - val_loss: 5.7377 - val_acc: 0.8622\n",
      "Epoch 45/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5790 - acc: 0.7496 - val_loss: 5.5898 - val_acc: 0.6413\n",
      "Epoch 46/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5697 - acc: 0.6805 - val_loss: 5.6327 - val_acc: 0.5971\n",
      "Epoch 47/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5683 - acc: 0.7675 - val_loss: 5.6091 - val_acc: 0.7067\n",
      "Epoch 48/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5677 - acc: 0.7082 - val_loss: 5.6229 - val_acc: 0.6935\n",
      "Epoch 49/100\n",
      "96000/96000 [==============================] - 9s 96us/step - loss: 5.5691 - acc: 0.7709 - val_loss: 5.6090 - val_acc: 0.7691\n",
      "Epoch 50/100\n",
      "96000/96000 [==============================] - 9s 95us/step - loss: 5.5707 - acc: 0.7888 - val_loss: 5.5928 - val_acc: 0.7295\n",
      "Epoch 51/100\n",
      "96000/96000 [==============================] - 9s 94us/step - loss: 5.5766 - acc: 0.7028 - val_loss: 5.5773 - val_acc: 0.7192\n",
      "Epoch 52/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.5670 - acc: 0.7261 - val_loss: 5.5823 - val_acc: 0.7803\n",
      "Epoch 53/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.5611 - acc: 0.7626 - val_loss: 5.6398 - val_acc: 0.8911\n",
      "Epoch 54/100\n",
      "96000/96000 [==============================] - 9s 93us/step - loss: 5.5771 - acc: 0.7939 - val_loss: 5.5744 - val_acc: 0.7780\n",
      "Epoch 55/100\n",
      "96000/96000 [==============================] - 9s 92us/step - loss: 5.5593 - acc: 0.7852 - val_loss: 5.5702 - val_acc: 0.8401\n",
      "Epoch 56/100\n",
      "96000/96000 [==============================] - 9s 92us/step - loss: 5.5754 - acc: 0.8432 - val_loss: 5.6509 - val_acc: 0.8445\n",
      "Epoch 57/100\n",
      "96000/96000 [==============================] - 9s 92us/step - loss: 5.5659 - acc: 0.8868 - val_loss: 5.5727 - val_acc: 0.8722\n",
      "Epoch 58/100\n",
      "96000/96000 [==============================] - 8s 88us/step - loss: 5.5748 - acc: 0.8426 - val_loss: 5.5917 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "96000/96000 [==============================] - 9s 89us/step - loss: 5.5635 - acc: 0.8496 - val_loss: 5.5713 - val_acc: 0.8685\n",
      "Epoch 60/100\n",
      "96000/96000 [==============================] - 10s 106us/step - loss: 5.5651 - acc: 0.8123 - val_loss: 5.5811 - val_acc: 0.7948\n",
      "Epoch 61/100\n",
      "96000/96000 [==============================] - 11s 115us/step - loss: 5.5686 - acc: 0.7879 - val_loss: 5.5735 - val_acc: 0.8903\n",
      "Epoch 62/100\n",
      "96000/96000 [==============================] - 14s 144us/step - loss: 5.5688 - acc: 0.8758 - val_loss: 5.5651 - val_acc: 0.8888\n",
      "Epoch 63/100\n",
      "96000/96000 [==============================] - 16s 164us/step - loss: 5.5655 - acc: 0.8920 - val_loss: 5.5668 - val_acc: 0.8628\n",
      "Epoch 64/100\n",
      "96000/96000 [==============================] - 17s 173us/step - loss: 5.5601 - acc: 0.8175 - val_loss: 5.5779 - val_acc: 0.9014\n",
      "Epoch 65/100\n",
      "96000/96000 [==============================] - 21s 217us/step - loss: 5.5681 - acc: 0.8506 - val_loss: 5.6158 - val_acc: 0.9706\n",
      "Epoch 66/100\n",
      "96000/96000 [==============================] - 14s 148us/step - loss: 5.5629 - acc: 0.9168 - val_loss: 5.5611 - val_acc: 0.8816\n",
      "Epoch 67/100\n",
      "96000/96000 [==============================] - 15s 160us/step - loss: 5.5629 - acc: 0.9100 - val_loss: 5.5985 - val_acc: 0.8783\n",
      "Epoch 68/100\n",
      "96000/96000 [==============================] - 22s 226us/step - loss: 5.5656 - acc: 0.9102 - val_loss: 5.5893 - val_acc: 0.9553\n",
      "Epoch 69/100\n",
      "96000/96000 [==============================] - 16s 166us/step - loss: 5.5578 - acc: 0.8649 - val_loss: 5.5652 - val_acc: 0.9529\n",
      "Epoch 70/100\n",
      "96000/96000 [==============================] - 14s 141us/step - loss: 5.5657 - acc: 0.9200 - val_loss: 5.6225 - val_acc: 0.8780\n",
      "Epoch 71/100\n",
      "96000/96000 [==============================] - 14s 150us/step - loss: 5.5634 - acc: 0.9071 - val_loss: 5.5808 - val_acc: 0.9502\n",
      "Epoch 72/100\n",
      "96000/96000 [==============================] - 14s 147us/step - loss: 5.5692 - acc: 0.8911 - val_loss: 5.6058 - val_acc: 0.9474\n",
      "Epoch 73/100\n",
      "96000/96000 [==============================] - 15s 154us/step - loss: 5.5584 - acc: 0.9216 - val_loss: 5.5578 - val_acc: 0.8577\n",
      "Epoch 74/100\n",
      "96000/96000 [==============================] - 13s 139us/step - loss: 5.5627 - acc: 0.9239 - val_loss: 5.5776 - val_acc: 0.8713\n",
      "Epoch 75/100\n",
      "96000/96000 [==============================] - 13s 140us/step - loss: 5.5745 - acc: 0.9046 - val_loss: 5.5681 - val_acc: 0.9041\n",
      "Epoch 76/100\n",
      "96000/96000 [==============================] - 18s 192us/step - loss: 5.5537 - acc: 0.9275 - val_loss: 5.5735 - val_acc: 0.9148\n",
      "Epoch 77/100\n",
      "96000/96000 [==============================] - 21s 215us/step - loss: 5.5692 - acc: 0.9214 - val_loss: 5.5977 - val_acc: 0.9608\n",
      "Epoch 78/100\n",
      "96000/96000 [==============================] - 17s 176us/step - loss: 5.5607 - acc: 0.9062 - val_loss: 5.5709 - val_acc: 0.8848\n",
      "Epoch 79/100\n",
      "96000/96000 [==============================] - 15s 156us/step - loss: 5.5573 - acc: 0.9421 - val_loss: 5.5670 - val_acc: 0.9886\n",
      "Epoch 80/100\n",
      "96000/96000 [==============================] - 15s 155us/step - loss: 5.5605 - acc: 0.9762 - val_loss: 5.5758 - val_acc: 0.9914\n",
      "Epoch 81/100\n",
      "96000/96000 [==============================] - 15s 156us/step - loss: 5.5659 - acc: 0.9476 - val_loss: 5.5651 - val_acc: 0.8714\n",
      "Epoch 82/100\n",
      "96000/96000 [==============================] - 16s 163us/step - loss: 5.5663 - acc: 0.9374 - val_loss: 5.5813 - val_acc: 0.9833\n",
      "Epoch 83/100\n",
      "96000/96000 [==============================] - 13s 136us/step - loss: 5.5565 - acc: 0.9650 - val_loss: 5.5587 - val_acc: 0.8989\n",
      "Epoch 84/100\n",
      "96000/96000 [==============================] - 14s 151us/step - loss: 5.5573 - acc: 0.9273 - val_loss: 5.5874 - val_acc: 0.9809\n",
      "Epoch 85/100\n",
      "96000/96000 [==============================] - 14s 149us/step - loss: 5.5674 - acc: 0.9547 - val_loss: 5.5712 - val_acc: 0.9785\n",
      "Epoch 86/100\n",
      "96000/96000 [==============================] - 19s 199us/step - loss: 5.5672 - acc: 0.9590 - val_loss: 5.5691 - val_acc: 0.9785\n",
      "Epoch 87/100\n",
      "96000/96000 [==============================] - 16s 171us/step - loss: 5.5560 - acc: 0.9788 - val_loss: 5.5757 - val_acc: 0.9852\n",
      "Epoch 88/100\n",
      "96000/96000 [==============================] - 13s 140us/step - loss: 5.5621 - acc: 0.9670 - val_loss: 5.5620 - val_acc: 0.9775\n",
      "Epoch 89/100\n",
      "96000/96000 [==============================] - 10s 108us/step - loss: 5.5598 - acc: 0.9834 - val_loss: 5.5737 - val_acc: 0.9825\n",
      "Epoch 90/100\n",
      "96000/96000 [==============================] - 16s 163us/step - loss: 5.5599 - acc: 0.9829 - val_loss: 5.5611 - val_acc: 0.9849\n",
      "Epoch 91/100\n",
      "96000/96000 [==============================] - 16s 165us/step - loss: 5.5652 - acc: 0.9665 - val_loss: 5.5695 - val_acc: 0.8766\n",
      "Epoch 92/100\n",
      "96000/96000 [==============================] - 18s 189us/step - loss: 5.5654 - acc: 0.9576 - val_loss: 5.5860 - val_acc: 0.9803\n",
      "Epoch 93/100\n",
      "96000/96000 [==============================] - 16s 163us/step - loss: 5.5538 - acc: 0.9818 - val_loss: 5.5540 - val_acc: 0.9657\n",
      "Epoch 94/100\n",
      "96000/96000 [==============================] - 15s 161us/step - loss: 5.5612 - acc: 0.9625 - val_loss: 5.5676 - val_acc: 0.9535\n",
      "Epoch 95/100\n",
      "96000/96000 [==============================] - 15s 158us/step - loss: 5.5587 - acc: 0.9686 - val_loss: 5.5590 - val_acc: 0.9944\n",
      "Epoch 96/100\n",
      "96000/96000 [==============================] - 16s 168us/step - loss: 5.5621 - acc: 0.9949 - val_loss: 5.5678 - val_acc: 0.9844\n",
      "Epoch 97/100\n",
      "96000/96000 [==============================] - 14s 150us/step - loss: 5.5545 - acc: 0.9922 - val_loss: 5.5815 - val_acc: 0.9865\n",
      "Epoch 98/100\n",
      "96000/96000 [==============================] - 14s 147us/step - loss: 5.5667 - acc: 0.9814 - val_loss: 5.5859 - val_acc: 0.9477\n",
      "Epoch 99/100\n",
      "96000/96000 [==============================] - 14s 144us/step - loss: 5.5564 - acc: 0.9760 - val_loss: 5.5962 - val_acc: 0.9982\n",
      "Epoch 100/100\n",
      "96000/96000 [==============================] - 16s 163us/step - loss: 5.5674 - acc: 0.9788 - val_loss: 5.5703 - val_acc: 0.9805\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/80\n",
      "96000/96000 [==============================] - 20s 206us/step - loss: 0.0420 - acc: 0.9816 - val_loss: 0.0167 - val_acc: 0.9932\n",
      "Epoch 2/80\n",
      "96000/96000 [==============================] - 13s 138us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.0091 - val_acc: 0.9967\n",
      "Epoch 3/80\n",
      "96000/96000 [==============================] - 13s 139us/step - loss: 0.0062 - acc: 0.9976 - val_loss: 0.0066 - val_acc: 0.9975\n",
      "Epoch 4/80\n",
      "96000/96000 [==============================] - 13s 131us/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0058 - val_acc: 0.9978\n",
      "Epoch 5/80\n",
      "96000/96000 [==============================] - 12s 125us/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.0055 - val_acc: 0.9982\n",
      "Epoch 6/80\n",
      "96000/96000 [==============================] - 13s 140us/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.0047 - val_acc: 0.9982\n",
      "Epoch 7/80\n",
      "96000/96000 [==============================] - 14s 143us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0039 - val_acc: 0.9987\n",
      "Epoch 8/80\n",
      "96000/96000 [==============================] - 13s 131us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0140 - val_acc: 0.9952\n",
      "Epoch 9/80\n",
      "96000/96000 [==============================] - 12s 125us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 10/80\n",
      "96000/96000 [==============================] - 13s 140us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0042 - val_acc: 0.9987\n",
      "Epoch 11/80\n",
      "96000/96000 [==============================] - 9s 98us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0038 - val_acc: 0.9987\n",
      "Epoch 12/80\n",
      "96000/96000 [==============================] - 10s 101us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0062 - val_acc: 0.9979\n",
      "Epoch 13/80\n",
      "96000/96000 [==============================] - 5s 56us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0041 - val_acc: 0.9987\n",
      "Epoch 14/80\n",
      "96000/96000 [==============================] - 5s 55us/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0056 - val_acc: 0.9986\n",
      "Epoch 15/80\n",
      "96000/96000 [==============================] - 5s 55us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0067 - val_acc: 0.9983\n",
      "Epoch 16/80\n",
      "96000/96000 [==============================] - 5s 55us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0037 - val_acc: 0.9987\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96000/96000 [==============================] - 5s 55us/step - loss: 8.5736e-04 - acc: 0.9998 - val_loss: 0.0046 - val_acc: 0.9985\n",
      "Epoch 18/80\n",
      "96000/96000 [==============================] - 5s 55us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0027 - val_acc: 0.9989\n",
      "Epoch 19/80\n",
      "96000/96000 [==============================] - 5s 55us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0045 - val_acc: 0.9988\n",
      "Epoch 20/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9992\n",
      "Epoch 21/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 8.8577e-04 - acc: 0.9998 - val_loss: 0.0030 - val_acc: 0.9988\n",
      "Epoch 22/80\n",
      "96000/96000 [==============================] - 7s 72us/step - loss: 8.6284e-04 - acc: 0.9997 - val_loss: 0.0025 - val_acc: 0.9991\n",
      "Epoch 23/80\n",
      "96000/96000 [==============================] - 8s 81us/step - loss: 4.7658e-04 - acc: 0.9998 - val_loss: 0.0036 - val_acc: 0.9989\n",
      "Epoch 24/80\n",
      "96000/96000 [==============================] - 7s 70us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0061 - val_acc: 0.9980\n",
      "Epoch 25/80\n",
      "96000/96000 [==============================] - 7s 76us/step - loss: 7.0111e-04 - acc: 0.9998 - val_loss: 0.0054 - val_acc: 0.9981\n",
      "Epoch 26/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 2.7435e-04 - acc: 0.9999 - val_loss: 0.0091 - val_acc: 0.9979\n",
      "Epoch 27/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 8.1534e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9984\n",
      "Epoch 28/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 8.6710e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9991\n",
      "Epoch 29/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 8.2743e-04 - acc: 0.9998 - val_loss: 0.0068 - val_acc: 0.9986\n",
      "Epoch 30/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 5.5502e-04 - acc: 0.9998 - val_loss: 0.0050 - val_acc: 0.9984\n",
      "Epoch 31/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 5.3690e-04 - acc: 0.9999 - val_loss: 0.0045 - val_acc: 0.9984\n",
      "Epoch 32/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 5.6721e-04 - acc: 0.9999 - val_loss: 0.0047 - val_acc: 0.9989\n",
      "Epoch 33/80\n",
      "96000/96000 [==============================] - 6s 63us/step - loss: 5.9963e-04 - acc: 0.9998 - val_loss: 0.0069 - val_acc: 0.9988\n",
      "Epoch 34/80\n",
      "96000/96000 [==============================] - 7s 72us/step - loss: 4.6501e-04 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 0.9992\n",
      "Epoch 35/80\n",
      "96000/96000 [==============================] - 6s 61us/step - loss: 5.7843e-04 - acc: 0.9998 - val_loss: 0.0046 - val_acc: 0.9985\n",
      "Epoch 36/80\n",
      "96000/96000 [==============================] - 6s 59us/step - loss: 2.0209e-04 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 37/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 2.6832e-04 - acc: 0.9999 - val_loss: 0.0036 - val_acc: 0.9988\n",
      "Epoch 38/80\n",
      "96000/96000 [==============================] - 6s 58us/step - loss: 6.8426e-04 - acc: 0.9997 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Epoch 39/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 1.0012e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9992\n",
      "Epoch 40/80\n",
      "96000/96000 [==============================] - 5s 56us/step - loss: 2.9847e-04 - acc: 0.9999 - val_loss: 0.0025 - val_acc: 0.9993\n",
      "Epoch 41/80\n",
      "96000/96000 [==============================] - 5s 56us/step - loss: 9.4378e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9995\n",
      "Epoch 42/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 8.1179e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9995\n",
      "Epoch 43/80\n",
      "96000/96000 [==============================] - 5s 56us/step - loss: 4.4254e-07 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9995\n",
      "Epoch 44/80\n",
      "96000/96000 [==============================] - 5s 57us/step - loss: 2.8777e-07 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9995\n",
      "Epoch 45/80\n",
      "96000/96000 [==============================] - 8s 82us/step - loss: 2.1263e-07 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9995\n",
      "Epoch 46/80\n",
      "96000/96000 [==============================] - 8s 81us/step - loss: 1.7364e-07 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9995\n",
      "Epoch 47/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.5202e-07 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9995\n",
      "Epoch 48/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.3984e-07 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9994\n",
      "Epoch 49/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.3255e-07 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9994\n",
      "Epoch 50/80\n",
      "96000/96000 [==============================] - 8s 82us/step - loss: 1.2798e-07 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9994\n",
      "Epoch 51/80\n",
      "96000/96000 [==============================] - 7s 77us/step - loss: 1.2508e-07 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9994\n",
      "Epoch 52/80\n",
      "96000/96000 [==============================] - 7s 75us/step - loss: 1.2319e-07 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9994\n",
      "Epoch 53/80\n",
      "96000/96000 [==============================] - 8s 82us/step - loss: 1.2192e-07 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9995\n",
      "Epoch 54/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.2106e-07 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9995\n",
      "Epoch 55/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.2047e-07 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9995\n",
      "Epoch 56/80\n",
      "96000/96000 [==============================] - 8s 81us/step - loss: 1.2007e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9994\n",
      "Epoch 57/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.1980e-07 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9994\n",
      "Epoch 58/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.1962e-07 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9994\n",
      "Epoch 59/80\n",
      "96000/96000 [==============================] - 8s 80us/step - loss: 1.1948e-07 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9994\n",
      "Epoch 60/80\n",
      "96000/96000 [==============================] - 7s 73us/step - loss: 1.1940e-07 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9994\n",
      "Epoch 61/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9994\n",
      "Epoch 62/80\n",
      "96000/96000 [==============================] - 7s 77us/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9994\n",
      "Epoch 63/80\n",
      "96000/96000 [==============================] - 8s 85us/step - loss: 1.1926e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9994\n",
      "Epoch 64/80\n",
      "96000/96000 [==============================] - 7s 71us/step - loss: 1.1925e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9994\n",
      "Epoch 65/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.1923e-07 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9994\n",
      "Epoch 66/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.1923e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Epoch 67/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.1922e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Epoch 68/80\n",
      "96000/96000 [==============================] - 7s 70us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Epoch 69/80\n",
      "96000/96000 [==============================] - 7s 77us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Epoch 70/80\n",
      "96000/96000 [==============================] - 8s 83us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Epoch 71/80\n",
      "96000/96000 [==============================] - 7s 70us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 72/80\n",
      "96000/96000 [==============================] - 7s 74us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 73/80\n",
      "96000/96000 [==============================] - 8s 82us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 74/80\n",
      "96000/96000 [==============================] - 7s 75us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/80\n",
      "96000/96000 [==============================] - 6s 66us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 76/80\n",
      "96000/96000 [==============================] - 6s 65us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 77/80\n",
      "96000/96000 [==============================] - 6s 68us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 78/80\n",
      "96000/96000 [==============================] - 6s 66us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 79/80\n",
      "96000/96000 [==============================] - 6s 66us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "Epoch 80/80\n",
      "96000/96000 [==============================] - 6s 66us/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9994\n",
      "(30000, 4, 10)\n",
      "(30000,)\n",
      "424-136 288\t\u001b[92m☑\u001b[0m 288\n",
      "470-228 242\t\u001b[92m☑\u001b[0m 242\n",
      "481-240 241\t\u001b[92m☑\u001b[0m 241\n",
      "712-894 -182\t\u001b[92m☑\u001b[0m -182\n",
      "302+841 1143\t\u001b[92m☑\u001b[0m 1143\n",
      "555+902 1457\t\u001b[92m☑\u001b[0m 1457\n",
      "160+136 296\t\u001b[92m☑\u001b[0m 296\n",
      "390+678 1068\t\u001b[92m☑\u001b[0m 1068\n",
      "872+418 1290\t\u001b[92m☑\u001b[0m 1290\n",
      "620-883 -263\t\u001b[92m☑\u001b[0m -263\n",
      "Accuracy : 99.32 % (29795 / 30000)\n"
     ]
    }
   ],
   "source": [
    "print('Validation with testing data...')\n",
    "right = 0\n",
    "\n",
    "modelOfNums, modelOfSign = buildModel(train_x, train_y)\n",
    "predNums = modelOfNums.predict(test_x.reshape(len(test_x), -1), verbose=0)\n",
    "predNums = predNums.reshape((len(test_y), 4, 10))\n",
    "print(predNums.shape)\n",
    "\n",
    "predSign = np.argmax(modelOfSign.predict(test_x.reshape(len(test_x), -1), verbose=0), axis=1)\n",
    "print(predSign.shape)\n",
    "\n",
    "\n",
    "for i in range(len(predSign)):\n",
    "    q = ctable.decode(test_x[i], type=\"expr\")\n",
    "    correct = transform(ctable.decode(test_y[i], type=\"ans\"))\n",
    "    \n",
    "    guessNum = ctable.decode(predNums[i], type=\"ans\")\n",
    "    if predSign[i] == 0:\n",
    "        guessSign = \"+\"\n",
    "    elif predSign[i] == 1:\n",
    "        guessSign = \"-\"\n",
    "    guess = int(guessSign + guessNum)\n",
    "    \n",
    "    if correct == guess:\n",
    "            right += 1\n",
    "    \n",
    "    if i >= len(predSign) - 10:\n",
    "        print(q, end=' ')\n",
    "        print(correct, end='\\t')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "            \n",
    "        \n",
    "print(\"Accuracy : {0:3.2f} %\".format((right / len(predNums)) * 100), end=' ')\n",
    "print(\"({} / {})\".format(right, len(predNums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDir = \"./model/\"\n",
    "modelOfNums.model.save(modelDir + \"nums_model\")\n",
    "modelOfSign.model.save(modelDir + \"sign_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
